{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "When Librosa loads an audio file, there is a default sample rate, which is the number of samples from the mp3's audio signal for one second. Therefore,\n",
    "to get the length of a song in real time we take the length of the read-in array and divide by the sample rate for that audio sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system packages\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# usual imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# tensorflow and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "## audio tools\n",
    "import librosa\n",
    "from torchaudio import info\n",
    "\n",
    "# my functions and classes\n",
    "from utilities import (\n",
    "    view_melspec,\n",
    "    read_metadata_file,\n",
    "    Batch_generator,\n",
    "    id_from_path,\n",
    "    attach_onehot_encoding,\n",
    "    mp3_to_mel_path\n",
    ")\n",
    "\n",
    "# for timing loops\n",
    "import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERY GLOBAL VARIABLES\n",
    "audio_dir = \"./data/fma_small/\"\n",
    "global_dur = 0.5\n",
    "global_sr = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code chunk is Super handy function that just searches for every mp3 file within the audio directory. \n",
    "My audio folder has a bunch of subfolders like '000', '099', etc, and the audio files are\n",
    "one level further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = librosa.util.files.find_files(audio_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what a typical load looks like. Specifying `sr=None` ensures that the file's default sample-rate is preserved. \n",
    "We can also specify the duration with `librosa.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_source, sr = librosa.load(filepaths[1], sr=None, duration=2)\n",
    "librosa.get_duration(example_source, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(example_source)\n",
    "plt.title(\n",
    "    f\"The first {librosa.get_duration(example_source, sr=sr)} seconds of an audio file\"\n",
    ")\n",
    "plt.xlabel(\"Sample Position\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_melspec(example_source, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How long does a typical load take?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "\n",
    "librosa.load(filepaths[0], sr=None, duration = global_dur)\n",
    "librosa.get_samplerate(filepaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my linux virtual machine, one second of audio takes between 143 and 214 milliseconds to load one second of audio (down to 129 ms if we don't force a sample rate). \n",
    "Multiplying this number by 8 is about how long it will take to load the entire dataset in. I estimate about 15 minutes for the whole FMA Small dataset.\n",
    "\n",
    "However, on my macbook it takes about 16 ms to load one second of audio in. For five seconds of audio, about 34 ms. This is much faster than the ubuntu machine! This means an estimated 134 seconds, or about two minutes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%timeit \n",
    "\n",
    "torchaudio.info(filepaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs a lot faster at 270 microseconds on my ubuntu virtual machine, so it will be a better tool to \n",
    "check for integrity. On the macbook it takes about 330 microseconds, a bit slower.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the only point where I will use `torchaudio` for the `torchaudio.info` method. This method\n",
    "tries to open the file without loading it into memory. This allows us to check\n",
    "for corrupted mp3 files. If this leads to a very long list of files, double check the integrity\n",
    "of your download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_files = []\n",
    "too_short_duration = 5.0  # seconds\n",
    "for file in filepaths:\n",
    "    try:\n",
    "        info_obj = info(file)[0]\n",
    "\n",
    "        # Add a file to the bad list if it is shorter than 5 seconds.\n",
    "        if info_obj.length / (info_obj.rate * info_obj.channels) < 5.0:\n",
    "            bad_files.append(file)\n",
    "\n",
    "    except RuntimeError:\n",
    "        bad_files.append(file)\n",
    "bad_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating memory cost"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Find out how much one second costs in memory\n",
    "example_source, sr = librosa.load(filepaths[0], sr=None, duration=1)\n",
    "\n",
    "# Estimate for all songs\n",
    "print(\n",
    "    f\"{(example_source.nbytes/10**9) * 8000} GB of memory for all 8000 songs\"\n",
    ")  # gigabytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Metadata "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code takes the giant metadata file coming with the FMA datasets and selects\n",
    "the track ids and the genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = os.path.join(\"data\", \"fma_metadata\", \"tracks.csv\")\n",
    "\n",
    "# Read in the metadata and process it. See utilities.py for explanation.\n",
    "meta_df = read_metadata_file(metadata_path, filepaths, bad_files)\n",
    "\n",
    "# shuffle the dataset\n",
    "meta_df = meta_df.sample(frac=1, random_state=1)\n",
    "\n",
    "# get a list of the genres\n",
    "genre_list = list(meta_df.genre.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check to make sure each path points to the right file\n",
    "meta_df[\"track_id\"].equals(meta_df[\"mp3_path\"].apply(lambda x: int(id_from_path(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec_dir = os.path.join(\".\", \"data\", \"fma_small_melspecs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will process `.mp3` files into melspectrograms, which are numpy arrays. Numpy arrays are saved as `.npz` files. The next cell will (most likely) be set to a raw cell, so that it does not run when executing the entire notebook.\n",
    "\n",
    "(Turning a cell from code to raw is like an on-off switch for a cell!)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "# This cell only to be executed when preprocessing reoccurs, e.g. \n",
    "# for first run of the notebook on your machine, or \n",
    "# when you wish to tweak parameters on the spectrograms.\n",
    "\n",
    "# Make all melspectrograms and save them to a new directory.\n",
    "\n",
    "melspec_dir = os.path.join(\".\", \"data\", \"fma_small_melspecs\")\n",
    "\n",
    "if not os.path.exists(melspec_dir):\n",
    "    os.mkdir(melspec_dir)\n",
    "\n",
    "def save_melspec(mp3_path, sr, duration, output_dir=melspec_dir):\n",
    "\n",
    "    output_path = os.path.join(output_dir, id_from_path(mp3_path) + \".mp3\")\n",
    "\n",
    "    src, _ = librosa.load(mp3_path, sr=sr, duration=duration)\n",
    "    np.savez(output_path, librosa.feature.melspectrogram(y=src, sr=sr))\n",
    "\n",
    "    return output_path\n",
    "\n",
    "meta_df['mel_path'] = meta_df['mp3_path'].apply(lambda x: save_melspec(x, sr=global_sr, duration=global_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df['mel_path'] = meta_df['mp3_path'].apply(lambda x: mp3_to_mel_path(x, melspec_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost done. Need to troubleshoot why the glob is failing to find the corresponding .npz file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "The class `Batch_generator` loads in batches one at a time so as to not load a huge amount of data into the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "training_generator = Batch_generator(\n",
    "    meta_df.iloc[:4800, :], batch_size=batch_size, sr=global_sr, duration=global_dur\n",
    ")\n",
    "validation_generator = Batch_generator(\n",
    "    meta_df.iloc[4800:6400, :], batch_size=batch_size, sr=global_sr, duration=global_dur\n",
    ")\n",
    "test_generator = Batch_generator(\n",
    "    meta_df.iloc[6400:, :], batch_size=batch_size, sr=global_sr, duration=global_dur\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "It's worth it to see if we can train a logistic regression model and see how well it does at classifying the genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = training_generator[0][0].shape[1:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logistic_reg = Sequential([\n",
    "    Flatten(data_format=None, input_shape = input_shape),\n",
    "    Dense(8, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "\n",
    "logistic_reg.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "logistic_reg.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logistic_reg.fit_generator(generator = training_generator,\n",
    "                           epochs=2,\n",
    "                           verbose=1,\n",
    "                           validation_data = validation_generator\n",
    "                          )\n",
    "\n",
    "                           validation_data = validation_generator,\n",
    "                           validation_steps = len(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "\n",
    "First we explore how well a traditional convolutional neural net works on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_fma",
   "language": "python",
   "name": "tf_fma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
